{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the concept of cyclical momentum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> Momentum is a gradient descent optimization approach that adds a percentage of the prior update vector to the current update vector to speed up the learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What callback keeps track of hyperparameter values (along with other data) during training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans-->A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training.\n",
    "\n",
    "This is exactly what we need as now we can get_weights() after each mini batch. The weights are stored in a weight_history list to be accessed later. A separate list is also maintained for the bias terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. In the color dim plot, what does one column of pixels represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans-->A digital color image pixel is just numbers representing a RGB data value (Red, Green, Blue). Each pixel's color sample has three numerical RGB components (Red, Green, Blue) to represent the color of that tiny pixel area. These three RGB components are three 8-bit numbers for each pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Does a batch normalization layer have any trainable parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> Batch normalization layer also has parameters of its own: Two learnable parameters called beta and gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. In batch normalization during preparation, what statistics are used to normalize? What about during the validation process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> Batch Norm is a normalization technique done between the layers of a Neural Network instead of in the raw data. It is done along mini-batches instead of the full data set. It serves to speed up training and use higher learning rates, making learning easier.Validation is done by taking the outputs from the first hidden layer and normalize them before passing them on as the input of the next hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Why do batch normalization layers help models generalize better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> By normalizing the activations of a layer, batch normalization can help to reduce overfitting and improve the generalization ability of the model. Reduces the need for careful initialization. Batch normalization can help reduce the sensitivity of the model to the initial weights, making it easier to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.Explain between MAX POOLING and AVERAGE POOLING is number eight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> Max Pooling returns the maximum value from the portion of the image covered by the Kernel. On the other hand, Average Pooling returns the average of all the values from the portion of the image covered by the Kernel.Max-pooling selects the maximum of the values in the input feature map region of each step and average-pooling the average value of the values in the region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. What is the purpose of the POOLING LAYER?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> The purpose of the pooling layers is to reduce the dimensions of the hidden layer by combining the outputs of neuron clusters at the previous layer into a single neuron in the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Why do we end up with Completely CONNECTED LAYERS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> The Fully connected layer is used for classifying the input image into a label. This layer connects the information extracted from the previous steps to the output layer and eventually classifies the input into the desired label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. What do you mean by PARAMETERS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans-->A model parameter is a configuration variable that is internal to the model and whose value can be estimated from data. They are required by the model when making predictions. They values define the skill of the model on your problem. They are estimated or learned from data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. What formulas are used to measure these PARAMETERS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans-->Number of parameters in a CONV layer would be : ((m * n * d)+1)* k), added 1 because of the bias term for each filter. The same expression can be written as follows: ((shape of width of the filter * shape of height of the filter * number of filters in the previous layer+1)*number of filters). Where the term “filter” refer to the number of filters in the current layer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
